all_training_data size: 89999
truncated training_date size: 16384
batch size: 256
category scores before training: 
tensor([[-0.9813, -0.4697],
        [-0.9722, -0.4752],
        [-0.9668, -0.4785],
        [-0.9703, -0.4764],
        [-0.9845, -0.4678],
        [-0.9789, -0.4712],
        [-0.9749, -0.4736],
        [-0.9715, -0.4757],
        [-0.9751, -0.4735],
        [-0.9783, -0.4715],
        [-0.9738, -0.4742],
        [-0.9633, -0.4806],
        [-0.9579, -0.4840],
        [-0.9612, -0.4820],
        [-0.9772, -0.4722],
        [-0.9705, -0.4762],
        [-0.9659, -0.4790],
        [-0.9620, -0.4814],
        [-0.9660, -0.4790],
        [-0.9692, -0.4770],
        [-0.9614, -0.4818],
        [-0.9507, -0.4886],
        [-0.9453, -0.4919],
        [-0.9520, -0.4877],
        [-0.9652, -0.4795],
        [-0.9614, -0.4818],
        [-0.9547, -0.4860],
        [-0.9502, -0.4889],
        [-0.9563, -0.4850],
        [-0.9517, -0.4879],
        [-0.9658, -0.4791],
        [-0.9555, -0.4855],
        [-0.9497, -0.4892],
        [-0.9569, -0.4846],
        [-0.9697, -0.4768],
        [-0.9666, -0.4786],
        [-0.9595, -0.4830],
        [-0.9558, -0.4853],
        [-0.9609, -0.4821],
        [-0.9560, -0.4852],
        [-0.9812, -0.4698],
        [-0.9709, -0.4760],
        [-0.9643, -0.4801],
        [-0.9714, -0.4757],
        [-0.9862, -0.4668],
        [-0.9789, -0.4712],
        [-0.9761, -0.4729],
        [-0.9680, -0.4778],
        [-0.9791, -0.4711],
        [-0.9742, -0.4740],
        [-0.9761, -0.4729],
        [-0.9666, -0.4786],
        [-0.9604, -0.4825],
        [-0.9651, -0.4795],
        [-0.9792, -0.4710],
        [-0.9755, -0.4732],
        [-0.9688, -0.4773],
        [-0.9671, -0.4783],
        [-0.9694, -0.4769],
        [-0.9693, -0.4770],
        [-0.9733, -0.4745],
        [-0.9633, -0.4807],
        [-0.9571, -0.4845],
        [-0.9631, -0.4808],
        [-0.9772, -0.4722],
        [-0.9726, -0.4750],
        [-0.9667, -0.4786],
        [-0.9631, -0.4808],
        [-0.9678, -0.4779],
        [-0.9659, -0.4790],
        [-0.9689, -0.4772],
        [-0.9582, -0.4838],
        [-0.9525, -0.4874],
        [-0.9566, -0.4848],
        [-0.9718, -0.4755],
        [-0.9672, -0.4783],
        [-0.9605, -0.4824],
        [-0.9575, -0.4842],
        [-0.9608, -0.4822],
        [-0.9618, -0.4816],
        [-0.9766, -0.4726],
        [-0.9670, -0.4784],
        [-0.9611, -0.4820],
        [-0.9665, -0.4787],
        [-0.9817, -0.4695],
        [-0.9755, -0.4732],
        [-0.9706, -0.4762],
        [-0.9675, -0.4781],
        [-0.9709, -0.4760],
        [-0.9710, -0.4759],
        [-0.9749, -0.4736],
        [-0.9647, -0.4798],
        [-0.9585, -0.4836],
        [-0.9638, -0.4804],
        [-0.9768, -0.4724],
        [-0.9726, -0.4750],
        [-0.9676, -0.4780],
        [-0.9632, -0.4807],
        [-0.9687, -0.4774],
        [-0.9682, -0.4777],
        [-0.9761, -0.4729],
        [-0.9664, -0.4788],
        [-0.9607, -0.4823],
        [-0.9645, -0.4799],
        [-0.9791, -0.4710],
        [-0.9731, -0.4746],
        [-0.9691, -0.4771],
        [-0.9652, -0.4795],
        [-0.9694, -0.4769],
        [-0.9722, -0.4752],
        [-0.9675, -0.4781],
        [-0.9564, -0.4850],
        [-0.9509, -0.4884],
        [-0.9542, -0.4863],
        [-0.9709, -0.4760],
        [-0.9636, -0.4805],
        [-0.9590, -0.4833],
        [-0.9546, -0.4861],
        [-0.9590, -0.4833],
        [-0.9622, -0.4813],
        [-0.9550, -0.4858],
        [-0.9439, -0.4928],
        [-0.9389, -0.4960],
        [-0.9452, -0.4920],
        [-0.9593, -0.4832],
        [-0.9547, -0.4860],
        [-0.9480, -0.4902],
        [-0.9434, -0.4932],
        [-0.9493, -0.4894],
        [-0.9452, -0.4920],
        [-0.9595, -0.4830],
        [-0.9487, -0.4898],
        [-0.9433, -0.4932],
        [-0.9496, -0.4892],
        [-0.9634, -0.4806],
        [-0.9594, -0.4831],
        [-0.9524, -0.4874],
        [-0.9487, -0.4898],
        [-0.9534, -0.4868],
        [-0.9500, -0.4889],
        [-0.9758, -0.4730],
        [-0.9650, -0.4797],
        [-0.9585, -0.4837],
        [-0.9656, -0.4793],
        [-0.9811, -0.4699],
        [-0.9731, -0.4747],
        [-0.9703, -0.4764],
        [-0.9616, -0.4817],
        [-0.9733, -0.4746],
        [-0.9682, -0.4777],
        [-0.9698, -0.4767],
        [-0.9597, -0.4829],
        [-0.9535, -0.4868],
        [-0.9580, -0.4840],
        [-0.9729, -0.4748],
        [-0.9685, -0.4775],
        [-0.9617, -0.4816],
        [-0.9597, -0.4829],
        [-0.9622, -0.4813],
        [-0.9625, -0.4812],
        [-0.9670, -0.4784],
        [-0.9565, -0.4849],
        [-0.9505, -0.4887],
        [-0.9559, -0.4853],
        [-0.9709, -0.4760],
        [-0.9655, -0.4793],
        [-0.9597, -0.4829],
        [-0.9559, -0.4853],
        [-0.9605, -0.4824],
        [-0.9595, -0.4830],
        [-0.9616, -0.4817],
        [-0.9502, -0.4888],
        [-0.9448, -0.4923],
        [-0.9487, -0.4898],
        [-0.9646, -0.4799],
        [-0.9592, -0.4832],
        [-0.9526, -0.4873],
        [-0.9492, -0.4895],
        [-0.9528, -0.4872],
        [-0.9540, -0.4865],
        [-0.9704, -0.4763],
        [-0.9602, -0.4826],
        [-0.9544, -0.4862],
        [-0.9592, -0.4832],
        [-0.9752, -0.4734],
        [-0.9684, -0.4775],
        [-0.9635, -0.4805],
        [-0.9600, -0.4827],
        [-0.9637, -0.4805],
        [-0.9646, -0.4799],
        [-0.9685, -0.4775],
        [-0.9578, -0.4841],
        [-0.9519, -0.4878],
        [-0.9572, -0.4845],
        [-0.9709, -0.4760],
        [-0.9660, -0.4790],
        [-0.9610, -0.4821],
        [-0.9563, -0.4850],
        [-0.9620, -0.4815],
        [-0.9613, -0.4819],
        [-0.9649, -0.4797],
        [-0.9544, -0.4862],
        [-0.9486, -0.4899],
        [-0.9535, -0.4868],
        [-0.9681, -0.4777],
        [-0.9623, -0.4813],
        [-0.9574, -0.4843],
        [-0.9531, -0.4870],
        [-0.9581, -0.4839],
        [-0.9585, -0.4836],
        [-0.9556, -0.4855],
        [-0.9440, -0.4928],
        [-0.9389, -0.4960],
        [-0.9433, -0.4932],
        [-0.9593, -0.4832],
        [-0.9526, -0.4873],
        [-0.9472, -0.4907],
        [-0.9425, -0.4937],
        [-0.9476, -0.4905],
        [-0.9481, -0.4902],
        [-0.9432, -0.4933],
        [-0.9323, -0.5003],
        [-0.9285, -0.5028],
        [-0.9348, -0.4987],
        [-0.9488, -0.4897],
        [-0.9440, -0.4928],
        [-0.9369, -0.4973],
        [-0.9326, -0.5001],
        [-0.9379, -0.4967],
        [-0.9329, -0.4999],
        [-0.9496, -0.4892],
        [-0.9392, -0.4959],
        [-0.9347, -0.4988],
        [-0.9412, -0.4946],
        [-0.9535, -0.4867],
        [-0.9507, -0.4885],
        [-0.9432, -0.4933],
        [-0.9398, -0.4955],
        [-0.9440, -0.4928],
        [-0.9397, -0.4955],
        [-0.9621, -0.4814],
        [-0.9515, -0.4881],
        [-0.9456, -0.4917],
        [-0.9546, -0.4861],
        [-0.9685, -0.4775],
        [-0.9621, -0.4814],
        [-0.9578, -0.4841],
        [-0.9493, -0.4894],
        [-0.9615, -0.4818],
        [-0.9521, -0.4876],
        [-0.9607, -0.4823],
        [-0.9500, -0.4890],
        [-0.9441, -0.4927],
        [-0.9496, -0.4892],
        [-0.9639, -0.4803],
        [-0.9598, -0.4829]])
epoch 0 loss 0.424542
time spent in 100 epoch 0:00:35.411316
epoch 100 loss 0.410303
time spent in 100 epoch 0:00:35.320720
epoch 200 loss 0.410443
time spent in 100 epoch 0:00:35.379727
epoch 300 loss 0.410358
time spent in 100 epoch 0:00:35.284500
epoch 400 loss 0.410255
time spent in 100 epoch 0:00:41.347780
epoch 500 loss 0.410338
time spent in 100 epoch 0:00:45.291376
epoch 600 loss 0.410482
time spent in 100 epoch 0:00:39.156891
epoch 700 loss 0.410195
time spent in 100 epoch 0:00:38.448689
epoch 800 loss 0.410458
time spent in 100 epoch 0:00:38.395576
epoch 900 loss 0.410235
time spent in 100 epoch 0:00:39.222550
epoch 1000 loss 0.410360
time spent in 100 epoch 0:00:38.603627
epoch 1100 loss 0.410387
time spent in 100 epoch 0:00:38.199212
epoch 1200 loss 0.410381
time spent in 100 epoch 0:00:37.928332
epoch 1300 loss 0.410289
time spent in 100 epoch 0:00:38.190157
epoch 1400 loss 0.410400
time spent in 100 epoch 0:00:36.987628
epoch 1500 loss 0.410300
time spent in 100 epoch 0:00:37.566363
epoch 1600 loss 0.410464
time spent in 100 epoch 0:00:36.677428
epoch 1700 loss 0.410369
time spent in 100 epoch 0:00:36.202766
epoch 1800 loss 0.410392
time spent in 100 epoch 0:00:35.583214
epoch 1900 loss 0.410403
time spent in 100 epoch 0:00:36.933048
epoch 2000 loss 0.410228
time spent in 100 epoch 0:00:37.196645
epoch 2100 loss 0.410398
time spent in 100 epoch 0:00:36.344174
epoch 2200 loss 0.410393
time spent in 100 epoch 0:00:36.010906
epoch 2300 loss 0.410408
time spent in 100 epoch 0:00:35.435080
epoch 2400 loss 0.410404
time spent in 100 epoch 0:00:35.700954
epoch 2500 loss 0.410304
time spent in 100 epoch 0:00:35.534147
epoch 2600 loss 0.410379
time spent in 100 epoch 0:00:35.534849
epoch 2700 loss 0.410422
time spent in 100 epoch 0:00:35.474119
epoch 2800 loss 0.410338
time spent in 100 epoch 0:00:35.561498
epoch 2900 loss 0.410348
time spent in 100 epoch 0:00:35.705244
epoch 3000 loss 0.410266
time spent in 100 epoch 0:00:35.584098
epoch 3100 loss 0.410424
time spent in 100 epoch 0:00:35.593548
epoch 3200 loss 0.410361
time spent in 100 epoch 0:00:35.964459
epoch 3300 loss 0.410311
time spent in 100 epoch 0:00:36.443099
epoch 3400 loss 0.410306
time spent in 100 epoch 0:00:35.726842
epoch 3500 loss 0.410338
time spent in 100 epoch 0:00:35.774450
epoch 3600 loss 0.410284
time spent in 100 epoch 0:00:35.596593
epoch 3700 loss 0.410296
time spent in 100 epoch 0:00:35.712869
epoch 3800 loss 0.410302
time spent in 100 epoch 0:00:35.546475
epoch 3900 loss 0.410278
time spent in 100 epoch 0:00:36.259878
epoch 4000 loss 0.410355
time spent in 100 epoch 0:00:36.376912
epoch 4100 loss 0.410350
time spent in 100 epoch 0:00:36.440523
epoch 4200 loss 0.410400
time spent in 100 epoch 0:00:36.036515
epoch 4300 loss 0.410310
time spent in 100 epoch 0:00:35.581927
epoch 4400 loss 0.410302
time spent in 100 epoch 0:00:35.531506
epoch 4500 loss 0.410369
time spent in 100 epoch 0:00:35.555334
epoch 4600 loss 0.410372
time spent in 100 epoch 0:00:35.442931
epoch 4700 loss 0.410343
time spent in 100 epoch 0:00:35.478297
epoch 4800 loss 0.410378
time spent in 100 epoch 0:00:35.524283
epoch 4900 loss 0.410297
time spent in 100 epoch 0:00:36.455971
epoch 5000 loss 0.410367
time spent in 100 epoch 0:00:36.643586
epoch 5100 loss 0.410269
time spent in 100 epoch 0:00:36.161643
epoch 5200 loss 0.410264
time spent in 100 epoch 0:00:35.539412
epoch 5300 loss 0.410246
time spent in 100 epoch 0:00:35.535005
epoch 5400 loss 0.410063
time spent in 100 epoch 0:00:35.738294
epoch 5500 loss 0.409816
time spent in 100 epoch 0:00:35.498855
epoch 5600 loss 0.407981
time spent in 100 epoch 0:00:35.717760
epoch 5700 loss 0.387230
time spent in 100 epoch 0:00:35.737484
epoch 5800 loss 0.317478
time spent in 100 epoch 0:36:30.473728
epoch 5900 loss 0.294847
time spent in 100 epoch 0:00:35.775993
epoch 6000 loss 0.281382
time spent in 100 epoch 0:00:38.000941
epoch 6100 loss 0.266038
time spent in 100 epoch 0:00:37.982023
epoch 6200 loss 0.376776
time spent in 100 epoch 0:00:36.215299
epoch 6300 loss 0.359532
time spent in 100 epoch 0:00:36.247825
epoch 6400 loss 0.347521
time spent in 100 epoch 0:00:39.270513
epoch 6500 loss 0.344544
time spent in 100 epoch 0:00:36.166011
epoch 6600 loss 0.323589
time spent in 100 epoch 0:00:36.044478
epoch 6700 loss 0.363620
time spent in 100 epoch 0:00:35.713414
epoch 6800 loss 0.385043
time spent in 100 epoch 0:00:35.720880
epoch 6900 loss 0.365272
time spent in 100 epoch 0:00:35.613985
epoch 7000 loss 0.393879
time spent in 100 epoch 0:00:35.615815
epoch 7100 loss 0.372682
time spent in 100 epoch 0:00:35.740486
epoch 7200 loss 0.372341
time spent in 100 epoch 0:00:35.600804
epoch 7300 loss 0.366658
time spent in 100 epoch 0:00:35.753231
epoch 7400 loss 0.362020
time spent in 100 epoch 0:00:35.654051
epoch 7500 loss 0.358944
time spent in 100 epoch 0:00:35.620802
epoch 7600 loss 0.347960
time spent in 100 epoch 0:00:35.449108
epoch 7700 loss 0.349924
time spent in 100 epoch 0:00:35.539715
epoch 7800 loss 0.374964
time spent in 100 epoch 0:00:35.484763
epoch 7900 loss 0.385460
time spent in 100 epoch 0:00:35.550082
epoch 8000 loss 0.377848
time spent in 100 epoch 0:00:35.525094
epoch 8100 loss 0.377563
time spent in 100 epoch 0:00:35.596246
epoch 8200 loss 0.379245
time spent in 100 epoch 0:00:35.589896
epoch 8300 loss 0.371709
time spent in 100 epoch 0:00:35.568532
epoch 8400 loss 0.368858
time spent in 100 epoch 0:00:35.465802
epoch 8500 loss 0.393245
time spent in 100 epoch 0:00:35.660809
epoch 8600 loss 0.387774
time spent in 100 epoch 0:00:35.554096
epoch 8700 loss 0.385757
time spent in 100 epoch 0:00:35.542946
epoch 8800 loss 0.383660
time spent in 100 epoch 0:00:35.726254
epoch 8900 loss 0.380934
time spent in 100 epoch 0:00:35.701516
epoch 9000 loss 0.380941
time spent in 100 epoch 0:00:35.848245
epoch 9100 loss 0.378681
time spent in 100 epoch 0:00:35.737025
epoch 9200 loss 0.382706
time spent in 100 epoch 0:00:35.535017
epoch 9300 loss 0.379583
time spent in 100 epoch 0:00:35.554094
epoch 9400 loss 0.386896
time spent in 100 epoch 0:00:35.681217
epoch 9500 loss 0.377525
time spent in 100 epoch 0:00:35.487767
epoch 9600 loss 0.375213
time spent in 100 epoch 0:00:35.410149
epoch 9700 loss 0.394873
time spent in 100 epoch 0:00:35.522493
epoch 9800 loss 0.393947
time spent in 100 epoch 0:00:35.563346
epoch 9900 loss 0.406045
category scores after training: 
tensor([[-0.1481, -1.9832],
        [-1.5970, -0.2263],
        [-0.1589, -1.9177],
        [-0.1587, -1.9189],
        [-0.1678, -1.8679],
        [-0.1579, -1.9237],
        [-0.1613, -1.9040],
        [-0.1638, -1.8900],
        [-0.2103, -1.6626],
        [-0.1683, -1.8651],
        [-0.1133, -2.2338],
        [-0.1529, -1.9535],
        [-0.1445, -2.0058],
        [-0.1556, -1.9371],
        [-0.1670, -1.8720],
        [-0.1610, -1.9057],
        [-0.1512, -1.9639],
        [-0.1677, -1.8683],
        [-0.1768, -1.8198],
        [-0.1552, -1.9397],
        [-0.1671, -1.8715],
        [-0.0751, -2.6258],
        [-0.1678, -1.8678],
        [-0.1625, -1.8975],
        [-0.1700, -1.8555],
        [-0.1613, -1.9041],
        [-0.1636, -1.8907],
        [-0.1500, -1.9712],
        [-0.2466, -1.5206],
        [-0.1560, -1.9351],
        [-0.1668, -1.8733],
        [-0.1587, -1.9193],
        [-0.1621, -1.8995],
        [-0.1560, -1.9348],
        [-0.1732, -1.8385],
        [-0.1515, -1.9622],
        [-0.1578, -1.9240],
        [-0.1679, -1.8672],
        [-0.1589, -1.9178],
        [-0.1627, -1.8963],
        [-0.1659, -1.8782],
        [-0.1563, -1.9332],
        [-0.1675, -1.8693],
        [-0.1506, -1.9674],
        [-0.1667, -1.8739],
        [-0.1598, -1.9127],
        [-0.1788, -1.8098],
        [-0.1704, -1.8538],
        [-0.1661, -1.8768],
        [-0.1717, -1.8466],
        [-0.1687, -1.8628],
        [-0.1550, -1.9411],
        [-0.1557, -1.9364],
        [-0.1575, -1.9263],
        [-0.1677, -1.8683],
        [-0.1673, -1.8707],
        [-0.1636, -1.8909],
        [-0.1685, -1.8641],
        [-0.1702, -1.8546],
        [-0.1677, -1.8681],
        [-0.1583, -1.9212],
        [-0.1595, -1.9146],
        [-0.1605, -1.9089],
        [-0.1554, -1.9387],
        [-0.1674, -1.8700],
        [-0.1507, -1.9669],
        [-0.1279, -2.1199],
        [-0.1671, -1.8714],
        [-0.1585, -1.9204],
        [-0.1689, -1.8616],
        [-0.2036, -1.6919],
        [-0.1541, -1.9460],
        [-0.1555, -1.9376],
        [-0.1603, -1.9095],
        [-0.1698, -1.8569],
        [-0.1561, -1.9342],
        [-0.1786, -1.8105],
        [-0.1627, -1.8962],
        [-0.1340, -2.0763],
        [-0.1742, -1.8335],
        [-0.1686, -1.8631],
        [-0.1368, -2.0568],
        [-0.1464, -1.9935],
        [-0.1554, -1.9385],
        [-0.1505, -1.9681],
        [-0.1740, -1.8342],
        [-0.1381, -2.0482],
        [-0.1531, -1.9525],
        [-0.1780, -1.8137],
        [-0.1507, -1.9668],
        [-0.1479, -1.9842],
        [-0.1677, -1.8683],
        [-0.1543, -1.9450],
        [-0.1558, -1.9362],
        [-0.1665, -1.8747],
        [-0.1575, -1.9262],
        [-0.1670, -1.8722],
        [-0.1668, -1.8730],
        [-0.6442, -0.7446],
        [-0.1660, -1.8776],
        [-0.1612, -1.9044],
        [-0.0941, -2.4097],
        [-0.1630, -1.8946],
        [-0.1617, -1.9020],
        [-0.1671, -1.8713],
        [-0.1584, -1.9206],
        [-0.1640, -1.8889],
        [-0.1624, -1.8977],
        [-0.1871, -1.7681],
        [-0.1586, -1.9195],
        [-0.1734, -1.8374],
        [-0.1466, -1.9927],
        [-0.1656, -1.8796],
        [-0.1578, -1.9246],
        [-0.1673, -1.8704],
        [-0.1647, -1.8850],
        [-0.1637, -1.8905],
        [-0.1680, -1.8665],
        [-0.1712, -1.8492],
        [-0.1691, -1.8607],
        [-0.1690, -1.8609],
        [-0.1724, -1.8431],
        [-0.1702, -1.8546],
        [-0.1562, -1.9334],
        [-0.1667, -1.8739],
        [-0.1539, -1.9474],
        [-0.1597, -1.9131],
        [-0.1704, -1.8534],
        [-0.1822, -1.7925],
        [-0.1593, -1.9156],
        [-0.1654, -1.8810],
        [-0.1517, -1.9609],
        [-0.1671, -1.8718],
        [-0.1584, -1.9207],
        [-0.1672, -1.8710],
        [-0.1514, -1.9623],
        [-0.1566, -1.9313],
        [-0.1669, -1.8727],
        [-0.1570, -1.9289],
        [-0.1639, -1.8893],
        [-0.1710, -1.8504],
        [-0.1707, -1.8519],
        [-0.1686, -1.8632],
        [-0.1473, -1.9879],
        [-0.1667, -1.8739],
        [-0.1620, -1.8998],
        [-0.1666, -1.8744],
        [-0.1689, -1.8618],
        [-0.1653, -1.8815],
        [-0.1647, -1.8848],
        [-0.0684, -2.7157],
        [-0.1550, -1.9405],
        [-0.1721, -1.8448],
        [-0.1568, -1.9300],
        [-0.1693, -1.8597],
        [-0.1488, -1.9787],
        [-0.1510, -1.9650],
        [-0.1673, -1.8706],
        [-0.1563, -1.9334],
        [-0.0485, -3.0508],
        [-0.1585, -1.9203],
        [-0.1652, -1.8822],
        [-0.1683, -1.8649],
        [-0.1665, -1.8751],
        [-0.1673, -1.8705],
        [-0.1504, -1.9687],
        [-0.1263, -2.1314],
        [-0.1515, -1.9621],
        [-0.1937, -1.7367],
        [-0.1603, -1.9096],
        [-0.1582, -1.9217],
        [-2.0415, -0.1391],
        [-0.1353, -2.0669],
        [-0.1572, -1.9280],
        [-0.1667, -1.8740],
        [-0.1653, -1.8817],
        [-0.1571, -1.9284],
        [-0.2060, -1.6809],
        [-0.1669, -1.8724],
        [-0.1620, -1.8998],
        [-0.1690, -1.8609],
        [-0.0307, -3.4994],
        [-0.1688, -1.8620],
        [-0.1568, -1.9300],
        [-0.1643, -1.8871],
        [-0.1509, -1.9659],
        [-0.1696, -1.8577],
        [-0.1734, -1.8378],
        [-0.1731, -1.8389],
        [-0.1271, -2.1259],
        [-0.1587, -1.9193],
        [-0.1908, -1.7505],
        [-0.1689, -1.8619],
        [-0.1565, -1.9319],
        [-0.1727, -1.8414],
        [-0.1660, -1.8779],
        [-0.1750, -1.8295],
        [-0.1660, -1.8778],
        [-0.1764, -1.8219],
        [-0.1575, -1.9258],
        [-0.1536, -1.9495],
        [-0.1842, -1.7826],
        [-0.1440, -2.0092],
        [-0.1588, -1.9184],
        [-0.1672, -1.8709],
        [-0.1530, -1.9527],
        [-0.1349, -2.0699],
        [-0.1674, -1.8700],
        [-0.0641, -2.7797],
        [-0.1667, -1.8735],
        [-0.1550, -1.9407],
        [-0.1757, -1.8253],
        [-0.1661, -1.8768],
        [-0.1557, -1.9369],
        [-0.1685, -1.8638],
        [-0.1540, -1.9468],
        [-0.1552, -1.9395],
        [-0.1675, -1.8695],
        [-0.1680, -1.8664],
        [-0.1682, -1.8654],
        [-0.1479, -1.9843],
        [-0.1785, -1.8109],
        [-0.1591, -1.9166],
        [-0.1548, -1.9419],
        [-0.1749, -1.8295],
        [-0.1618, -1.9011],
        [-0.1628, -1.8953],
        [-0.1506, -1.9673],
        [-0.1683, -1.8647],
        [-0.1615, -1.9029],
        [-0.1672, -1.8710],
        [-0.1587, -1.9188],
        [-0.1668, -1.8734],
        [-0.1555, -1.9376],
        [-0.1685, -1.8640],
        [-0.1509, -1.9657],
        [-0.1561, -1.9341],
        [-0.1690, -1.8612],
        [-0.1638, -1.8901],
        [-0.1667, -1.8739],
        [-0.1658, -1.8788],
        [-0.1695, -1.8585],
        [-0.1644, -1.8865],
        [-0.1555, -1.9377],
        [-0.1674, -1.8698],
        [-0.1620, -1.9001],
        [-0.1779, -1.8139],
        [-0.1590, -1.9174],
        [-0.1628, -1.8953],
        [-0.1749, -1.8299],
        [-0.1147, -2.2219],
        [-0.1647, -1.8850],
        [-0.1674, -1.8698],
        [-0.1554, -1.9382],
        [-0.1694, -1.8592],
        [-0.1614, -1.9035]])
time spent total: 1:36:18.842519
